 we have we have been talking about this audio right audio processing with respect to speaker recognition speech recognition or or any such related task right but you also know that with any of these security technologies there can be attacks or there can be people who are who have any kind of ill intention who would like to defraud the system right who would like to fool the system have you heard of any such examples any such real world examples where any kind of security system is in place be it biometrics space voice any of those and there have been cases where these systems have been fooled anybody remembers any such instance would like to share you have to speak up okay all so there have been several such instances not only in I'm audible right somebody please speak up I'm not able to hear you once to see the text and all okay so there have been several such instances with respect to different kinds of tasks automation tasks that we have been performing right and specifically in speech these are all the news clippings that you see of documented cases okay one of the interesting ones the one that you see at the bottom Citibank launches voice passwords in India right so Citibank launched voice passwords you can gain access to accounts by using by speaking out your passwords and you will also see in captcha right that you can speak out whatever so there are image captchas and then there are audio captchas also that are there for people with special requirements they can speak out audio captchas right so but these can be fooled using some of these technologies and this is what also happened in some of these cases for example this Adobe Voco they have a photoshop for voice which can lead to concerns we have robot speech simulator and several other such things that have been proposed in the literature and similar counterparts have also been proposed which can be used to defraud okay so specifically speaking this line of research presentation attack like we call it or spoofing this has been in the community for like 15 years or so now the research started the first competition around this it's called as the spoofing audio spoofing competition AASP audio spoofing verification competition we call it so this competition started I think around 2009 or so in the research community right at that time they were looking at some very specific kinds of attacks and I'll show you what those kinds of attacks were but these competitions went they're still running those competitions are still running to evaluate the performance or of these attack detection algorithms or manipulation detection algorithms but after a few years that this research on presentation of spoofing started ISO got involved this international standards organization and they created a standards document on presentation attacks earlier we used to call it spoofing but then ISO termed it as presentation attack so anything that is presented in front of a biometric system it can be attacked right so and then there are different kinds of attacks so earlier the nomenclature used to be like real spoof but then they proposed this nomenclature of bona fide and impostor so bona fide is a real one right so in this case with respect to face if you see bona fide is the real face so you would enroll a real face a real face is coming as a query so this is predicted as genuine right but then you could have impostors now what are those impostors impostors is anyone who is trying to fraudulently gain access to the system right now this is something called as a zero effort impostor what is a zero effort impostor so let's say I want to gain access to your account right I just go in front of the biometric system and I give my biometric let's say that biometric is face or that biometric is audio I just give that biometric as I just without any effort of trying to look like you or trying to impersonate your voice or fingerprint whatever that modality is I just go using my characteristics and try to gain access to your account right so that is something called a zero effort impostor which is in which case it is very likely that I will not be able to gain access it will be it will be a failed attempt right but then there are cases in which one can get access and go back to Doddington where we had these goat, lamb, sheeps and holes right there are some cases there are some individuals who are easy to impersonate so if these are easy to impersonate people even with zero effort impostor I might just be able to gain access depending on a lot of characteristics lot of factors right but then what I can also do is do a bit more effort in trying to gain access to your account okay now in what ways can I try to gain access to your account let's say if it is audio in what ways can I get access to your account can you think of it if I have to spoof an audio data an audio signal if you were given this task of spoofing what will you do how will you create a spoof of audio let's say you have to gain access to my account what will you do I'm waiting for the answers try to text try to speak in your my audio okay okay so try to speak in my audio okay yes nearly muslim scooping in your phone likewise okay anything else record your voice and and then feed it record my voice and feed it that is good what else use the text speech model and text that my name is inja please open the account this type of thing so that the model create an audio and see that in the network we can also make a deep pick of the voice we can also make a deep pick of all right so all of these are valid answers right and the method of okay let me just play this audio signals for you in order to play this I think I'll have to go to the drive okay let me go to the drive just listen to this audio and tell me if it is correct okay whose voice is this sharukh obviously right do you think it is a real voice of sharukh or this is any kind of AI attack you cannot hear the audio yeah we are not able to hear you cannot hear my audio or you cannot hear the audio I just played videos yeah those that audio you couldn't hear the audio I played right yes ma'am let give me one second let me stop presenting can you hear now tysp cons some gaps In that thin sharp-tharse voice, there is some gap. He is used to speaking with gaps. No? Yes, yes. Anybody else would like to give it a try? Okay, let me play another one. I can say that I can only say that I can only say that. What about this? Yes ma'am, I think real-wise. Ambesh Dhani. Okay. No, I don't think it's real. The tonality is a little bit changed. Okay, so both of these guys are generated audios. Okay. Shahrukh Khan as well as Amrish Kuri. This Amrish Kuri ka audio was generated after he passed away. Right? And this Shahrukh Khan ka audio, so there is this entire video that was generated a few years back by Cadbury's. And they did a ad with Shahrukh Khan's voice for local Kirana stores. Right? Because if you hear the audio, he is talking about local Kirana store waale se ye le na, or PAS ke Sharma ji ki Dukan se ye le na and all of that. Right? These guys can't afford Shahrukh Khan. These local Kirana stores and local uncle and auntie shops, they can't afford it. So, they, Cadbury's used Gen AI, I think it was Cadbury's, they used Gen AI to create this, create this entire ad. Right? And that ad, you can find that ad on YouTube. It should be still there. So, benefit is, you can create, but then I don't know if they took permission from Shahrukh Khan or not. Right? You can, you can create all those sorts of things. And I mean, you guys know that we are talking about beef fakes till we are having a discussion on whether it is fake or not. Think about any normal person who does not know the concept of beef fakes so well that how good or how bad it is. How would they differentiate between the two? Right? So, there is an entire categorization of spoofing attacks. You can generate samples based on AI methodologies and using some non AI methodologies as well. Right? So, if you talk about, obviously these non AI methodologies came earlier and this, when I was talking about the research started like 15 years back, we started with non AI methodologies. Right? And non AI methodologies, there are four, five points of attacks which are more common ones. The first one is your replay. Right? So, replays, I think Ravi suggested it earlier that what you can do is you have my audio right now that I am, you have so many required audio samples of me from over multiple classes. Right? If you want to gain access to my account, you can take this audio and you can replay it whenever, take out words or do something of that sort and replay it to gain access to my account. Right? So, that is your replay attack. Okay? To give you an example of replay with respect to a face, this is how you can actually visualize it. So, this is your real audio, real frames from real video. These are again your frames from real video. But what you can do is, you can record this video and replay. Let's say I was trying to gain access to my KYC or my account or I want to be present in a meeting, put attendance using a face biometric system. So, you can use that and gain access multiple times using that. Right? So, again, several years back, okay, there are these school teachers in some country, I think it was Pakistan. So, there was this grant coming in from United Nations for school teachers. And they were mandated to put attendance using case biometrics. So, there was grant coming in for promoting school education in different countries. So, they said that we've and stipend of, sorry, and salaries of teachers and everybody was going in. They kind of mandated that in order to ensure that teachers go to school every day. So, you have to go to school, you have to put your, you have to take a selfie and you have to post it on some server with a date and timestamp so that your attendance is recorded. Right? And based on that attendance, the salary was released every month. Right? So, what some of the teachers used to do that what I'll do is today I'll take a picture, I'll go to school, I'll take five pictures for me. Okay? And what I can do is tomorrow if I want to skip school, I have multiple pictures. So, I'll take this picture and I'll click another picture of this from the phone. Okay? Or I'll take a, I'll take a printout of this, click another picture and upload this. So, the date and timestamp that comes with the photo in the metadata that will be for tomorrow because I clicked the photograph from the photograph, the, the, the impersonation one that I had. That I clicked tomorrow. So, then, then date and timestamp will be fixed and I'll have my attendance marked. Right? The same kind of thing can be done with respect to audio where you can capture these sentences and you can replay it again and again. Right? So, today I go with the background and all I can capture the audio and wherever required I can replay the audio to gain access or to provide incorrect information or whatever is the requirement. Right? So, that is your replay attack. Impersonation, impersonation is simple. We understand that if you, if you try to impersonate someone. And this impersonation can be done by different methods. Earlier this used to be non AI based. And in non AI based, it would be, what would be non AI based impersonation? It would be something like, like we, there are mimicry artists. Right? There are mimicry artists who can very well mimic the audio of Shah Rukh Khan, Amitabh Bachchan or anybody. Right? They can mimic anybody's voice. So, that mimicry would be, that mimicry if used for impersonation would be considered as an attack. And that, that would be, that, that would be impersonation to gain access. Right? The another one is copy move. Right? What is copy move? Copy move is something where I can take an audio. Take an audio signal. And take some parts of an audio from one place to other in the audio. Right? And this, I think happened in the elections this time. When, when we had general elections. Yeah. When we had general election this time. This is a news clipping I got from YouTube. And let me just play this for you. You can see the screen? The YouTube? No, no, the screen is not shared. Oh, screen is not shared. Oh, sorry, sorry, sorry. I, the screen got unshared. Okay. Can you see it now? Yes. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. So, when I can contrast the screen, I'm not able to hear the voice. Oh, you are again not able to hear the voice? Why is it doing this? It does anybody know? Uhâ€¦ Ma'am, I guess instead of sharing the screen, you could share a tab. I guess instead of sharing the screen, you could share the tab. That would allow us to hear the audio in the YouTube tab. Okay. Let me do that. Entire screen. Chrome tab. Okay. Can you hear this now? Yes, yes. Okay. Let me just play the first talk very quickly. See, this is the first audio which was claimed to be the original audio. Actually, right? Now, let me play you the fake audio. See, what happened here? Lip is not sinking with voice. Lip is not sinking with voice. Okay. What is the kind of attack? What are you trying to do here? So, what they did in this is, they took some of, they had the original video, right? They had the original video of Mr. Amit Shah, right? And in some places, they didn't change the entire audio or the entire video. What they did? This, in between, in the beginning of the speech, he used this word, not that he used, they inserted this word, Gair Samvidhanik, right? When he was referring to this, they inserted the word, Gair Samvidhanik. And then, towards the end, when he was saying that this reservation will continue, Adhikar Denge, they said, is good, Samad Denge. So, in Poppy move, what we do, you take a word from somewhere and you insert it, right? Or, you can change phrases. You have a phrase spoken at one place. You pick up this phrase and you insert it somewhere else. Now, in this case, what they did was, this, this, Gair Samvidhanik is probably the word which they might have found, they might not have found anywhere to be in the same speech, right? Now, if you, if they did not find that word in the same speech with the same attire, because there is video also. Now, see, this is multi-model scooping that is happening. So, you have to spoof the video and you also have to scoop the audio along with it. So, lip syncing and everything else has to go hand in hand very well, right? So, if he had spoken the word Gair Samvidhanik anywhere, anytime, you can pick up that word and insert it here, right? But since you have to, you have to do a complete multi-model scooping, multi-model generation of, of the attack, you need him to speak. You need a video of him speaking the same thing with lip sync and everything and that has to be inserted in the middle and do, teen baar wo kya because the sentence has to flow in place, right? So, earlier, jab hum AI based attack, this copy move we used to do, this used to be a very simple copy paste here and there, right? Either, either cut, cut copy paste, cut copy move is something we used to say, right? So, ya to delete kardo ya copy move kardo either so that, but now what has happened and, and in the, in earlier days, it used to be just, if you have an audio of the person speaking those sentences or words only then you could create this. But today with this generative AI algorithms what you can do is you can also create these complete instances of, of people speaking, right? Even if they, if they, even if they weren't existing with the team. So, this is a combination, this Amit Shaka video that you just saw, Amit Shaka video plus audio that we saw, it was a combination of copy move along with speech synthesis, right? Along with speech synthesis that we were able to generate. So not only speech synthesis, probably video synthesis also that happened along with it because sirif speech synthesis karo we, to the entire thing has to be shifted further back, right? So, so that is what we did, right? And then audio splicing is audio ko leke usko splice karke you can actually, so audio splicing would be similar to copy move where copy move maybe was just shifting out. Audio splicing where you can actually remove out words completely or phrases completely, right? So earlier again this used to be all non AI. Today you can do all of it with AI and what you will get is a lot more simplified version, not simplified, a lot more smooth out version of the attacks, right? So replay kar sakte ho usse, we can do replay with using AI based attacks, you can do impersonation, you can do copy move, audio splicing using all of it, using AI, genitive AI and what it is, right? And in AI based the two main categories that you have is you can do speech synthesis. So in speech synthesis what we do? In speech synthesis we can have the complete speech synthesized, right? With you and you can do it in whosoever's voice you want, okay? So did I play you that song of Hafef Aslam and Arjeet Singh sometime in the past? You guys remember? You have to speak out. I am not able to see the chat. I remember that there was no means you have had not played any song or part of it. You don't remember? Okay, I will search for it and I will show it to you. So you could do speech synthesis. So generate something completely in like Amrishpur is audio, right? So that Amrishpur is audio voice a complete synthesis. We just have, we don't, we had completely new generation of that audio, right? And then you could do voice conversion and in voice conversion you can take whatever I'm talking about and you can have it present in let's say Freya's voice or you can have it present in Shyam's voice. So the complete lecture is being given by any other student be it Freya, be it Shyam, be it anybody else, right? So the entire voice conversion can be done using AI based effects. Now this broad category of being able to impersonate or being able to create new things, change from one to other. This, this broad line of attacks is called as deepfake attacks. Images you have seen a lot of it in the, in the general news and stuff. But this is very, very much possible, very much even prevalent I would say. So the quality of this project along with my view has talked really quickly here I will and enjoy crazy-speaking areas and slow quality times. Then you can't assume . Sounds like getting high quality in the Qualysia group and the other.