 We have been talking about this audio processing with respect to speaker recognition, speech recognition or any such related task. But you also know that with any of these security technologies, there can be attacks or there can be people who are who have any kind of intention who would like to defraud the system, right who would like to fool the system. Have you heard of any such examples, any such real world examples where any kind of security system is in place, the biometrics, space, voice, any of those and there have been cases where these systems have been fooled, anybody remembers any such instance, would like to share. I am going to have to speak up. Is he going to come in? Okay, all right. So, there have been several such instances not only in, I am audible, right. Somebody please speak up, I am not able to hear you guys to speak the text and all. Okay, so there have been several such instances with respect to different kinds of tasks, automation tasks that we have been performing, right. And specifically speech, these are all the news clippings that you see of documented cases. Okay, one of the interesting ones, the one that you see at the bottom, city band launches, voice passwords in India, right. So, city band launched, voice passwords, you can gain access to accounts by speaking out your passwords and you will also see in capture, right. You can speak out whatever, so there are image captures and then there are audio captures also that are there. For people with special requirements, they can speak out audio captures, right. So, but these can be fooled using some of these technologies and this is what also happened in some of these cases. For example, this adob bow bow, they have a photoshopped voice which can lead to concerns. We have robot speech simulator and several other such things that have been proposed in the literature and similar counterparts have also been proposed which can be used to decryon. Okay, so specifically speaking, this line of research, the presentation attack like we call it or spoofing, this has been in the community for like 15 years or so now. The research started the first competition around this. It's called as the spoofing audio spoofing competition, AASB audio spoofing verification competition we call it. So, this competition started I think around 2000, we never know in the research community, right. At that time, they were looking at some very specific kinds of attacks and I'll show you what those kinds of attacks were. But these competitions, when they're still running, those competitions are still running to evaluate the performance or of these attack detection algorithms or manipulation detection algorithms. But after a few years that these research on presentation of spoofing started, I also got involved in this International Standards Organization and they created a standards document on presentation attacks. Earlier we used to call it spoofing but then I also termed it as presentation attacks. So, anything that is presented in front of a biometric system, it can be attacked, right. So, and then there are different kinds of attacks. So, the earlier the nomenclature used to be like real spoof but then they proposed this nomenclature of bona fide and impostor. So, bona fide is a real one, right. So, in this case with respect to space, if you see bona fide is the real face, so you would enrol a real face, a real face is coming as query. So, this is predicted as genuine, right. But then you would have impostors. Now, one of those impostors is anyone who is trying to fraudulently get an access to the system. Now, this is something called an zero effort impostor. What is a zero effort impostor? So, let's say I want to gain access to your account, right. I just go in front of the biometric system and I give my biometric, let's say that biometric space or that biometric audio, I just give that biometric as, I just without any effort of trying to look like you or trying to impersonate your voice or thing of guilt, whatever their modalities, I just go using my characteristics and try to gain access to your account, right. So, that is something called zero effort impostor, which is in which case it is very likely that I will not be able to gain access. It will be filled at any time, right. But then there are cases in which one can get access and go back to the dotting function, when where we had these both lamb sheep's and wolves, right. There are some cases, there are some individuals who are easy to impersonate. So, if these are easy to impersonate people, even with zero effort impostor, I might just give you to gain access to depending on, depending on a lot of characteristics, a lot of factors, right. But then what I can also do is do a bit more effort in trying to gain access to your account. Now, in what ways can I try to gain access to your account, let's say if it is audio, in what ways can I get access to your account. Can you think of it? If I have to spoof an audio data and audio signal, if you were given this task of seeing what will you do, how will you create a spoof of audio. Let's say you have to gain access to my account, what will you do. I am waiting for the answers. Try to try to speak in your, we like to, like my name is, which I have been talking about. So, try to speak in my audio. Yes, nearly must have spoken in your form, like why. Okay, anything else. Record your voice and then feed it. Record my voice and feed it. That is good. What else? Use the text to speak model and text that will, my name is, which I have been talking about. So, that model created audio and speech that in the net. We can also make a deep break of the text. We can also make a deep break of the text. So, all of these are valid answers. And the method of, let me just play this audio signals for you in order to play this, I think I will have to go to the drive. Okay, let me go to the drive. Just listen to this audio and tell me if it is correct. Okay, so whose voice is this? Charo Khan of this key. Do you think it is a real voice of Charo Khan of this is entering a teyer tab? You cannot hear the audio. You cannot hear my audio or you cannot hear the audio, I just played. Videos, yes, those that audio. You couldn't hear the audio, I played, right? Yes ma'am. Okay, let me give me one second. Let me stop presenting. Oh, in here now? That's the style of Chishma, the next one is heaven, I operation failin. Yes ma'am. Okay. Siddhi Vinay, he can like run it, say, let us smartphone, correct God. So, ma'am can ask sir to be close to God. That's correct. Okay, when did this picture generate a sound? It is how it generate a sound. How? Some get in sharp half voice, there is some get. He is used to speaking with the apps. No? Yes, yes. Anybody else would like to give a try? Okay, let me play another one. What about this? Yes ma'am, I think real voice. I am very sorry. Okay, no, I don't think it is real. The tone, the tone, the additives are a little bit changed. Okay, so both of these guys are generated audio. Okay, Shahrukh Khan as well as Amrish Kuri, the Amrish Kuri ka audio was generated after he passed away. And this Shahrukh Khan's audio, so there is this entire video that was generated a few years back by Katbury's. And they did add with Shahrukh Khan's voice for local Kiranah stores. Right, because if you hear the audio, he is talking about local Kiranah store, or Pashtay Sharmajit, you can't say, Geylena and all of that. These guys can't afford Shahrukh Khan, these local Kiranah stores and local Angolan art shops. They can't afford Shahrukh Khan. So they, Tanbury's use Genie, I think it was Tanbury's, they use Genie to create this entire add. And let add, you can find the add on YouTube, it's to be still there. So, benefitoners, you can create, but then I don't know if they took permission from Shahrukh Khan or not. Right, you can create all those sort of things. And I mean, you guys know that we are talking about B-Picks, till we are having a discussion on whether it is fake or not. Think about any normal person who does not know the concept of B-Picks so well, that how good or how bad it is, how would they differentiate between the two. Right, so there is an entire categorization of spoofing attacks. You can generate samples based on AI methodologies and using non-AI methodologies as well. So, if we talk about, obviously these non-AI methodologies came earlier in this, when I was talking about the recent start of like the previous work, we started with non-AI methodologies. And non-AI methodologies, therefore five kinds of attacks, which are more common ones, the first one is your replay. So, replays, I think Ravi's suggested it earlier, that what you can do is, you have my audio right now, that I, you have so many required audio samples of me from multiple classes, right. If you want to gain access to my account, you can, you can take this audio and you can replay it whenever, take out words or do something of that sort and replay it again access to my account, right. So, that is your replay attack, okay. To give you an example of replay with respect to a face, this is how you can actually visualize it. So, this is your real audio, real frames from real video, these are again your frames from real video. But what you can do is, you can record this video and replay, let's say I was trying to gain access to my KYC or my account or I want to be present in a meeting, put attendance using a face-by-meted system, you can use that and gain access multiple times using that, right. So, again, several years back, okay, there are these cool features in some country, I think, because Pakistan. So, there was this grant coming in from United Nations for school teachers. And they were mandated to put attendance using face-by-meted. So, there was grant coming in for promoting school education in different countries. So, they said that we, and, and salaries of teachers and everybody was going in, they kind of mandated that in order to ensure that teachers go to school every day. So, you have to go to school, you have to put your, if you take a selfie and you have to post it on some server with, with a date and time stamp, so that your attendance is recorded, right. And based on that attendance, this algae was released every month, right. So, what some of the teachers used to do that what I'll do is today, I'll take a picture, I'll go to school, I'll take five pictures for me, okay. And what I can do is tomorrow, if I want to skip school, I have multiple pictures, I'll take this picture and I click another picture of this from the phone, or I'll take a printout of this, click another picture and upload this. So, the date and time stamp that comes with the photo in the metadata, that will be for tomorrow, because I clicked the photograph, from the photograph, the, the impersonation one that I had, that I clicked tomorrow. So, then, then date and time stamp will be clicked and I'll have my attendance mark, right. The same kind of thing can be done with respect to audio, where you can capture these sentences and you can replay it again and again. Right. So, today I go with the background and all, I can capture the audio and wherever required, I can replay it all here, to gain access or to provide incorrect information or whatever is the requirement. So, that is your replay attack. impersonation is simple, we understand that if you, if you try to impersonate someone, and this impersonation can be done by different methods, earlier this used to be non-AI based and in non-AI based, it would be what would be non-AI based impersonation, it would be something like, like we, there are mimicry artists, right. There are mimicry artists who can very well mimic the audio, Shahrukh Khan Amta Bachchan or, or anybody, right. They can mimic anybody's voice. So, so that mimicry would be, that mimicry, it's used for impersonation could be considered as an attack and that, that would be, that, that would be impersonation to gain access, right. The another one is copy move, right. What is copy move? Copy move is something where I can take an audio signal and take some parts of the audio from one place to other in the audio, right. And this, I think happened in the elections this time, when we had general elections, when we had general elections this time, this is a news clipping I got from YouTube, and let me just play this for you. You can see the screen, the YouTube. One of the screen did not share it. Oh screen is not shared. Oh sorry sorry sorry, I need this screen got unshared. Okay, can you see it now? Yes. I'm not able to hear the voice. You are again not able to hear the voice. Why is it doing this anybody knows? I guess instead of sharing the screen, you could share the tab that would allow us to hear the audio in YouTube tab. Okay. Let me do that. Entire screen. Okay. Can you hear this now? Let me just play the first talk you very quickly. Let's see. What is the answer? What is the answer? What is the answer? See this is the first audio which was claimed to be original audio. Actually, right. Now let me play you the fake audio. See what happened here? Lift is not syncing with voice. In second voice. What is the kind of attack? What we are trying to do here? So what they did in this is they took some of the original video. They had the original video of Mr. Amit Shah. And in some places they did not change the entire audio or the entire video. What they did? In the beginning of the speech, they inserted this word, Gair Samrithane. When he was referring to this, they inserted the word Gair Samrithane. And then towards the end, when he was saying that this reservation will continue or the Dikar Dengay, they said, he is going to be able to do some of this. Now in top of what we do, you take a word from somewhere and you insert it. Or you can change phrases. You have a phrase spoken at one place. You pick up this phrase and you insert it somewhere else. Now in this case, what they did was this Gair Samrithane is probably the word which they might have found, they might not have found anywhere to be in the same speech. Now if they did not find that word in the same speech with the same attire, because there is video also. See, this is multi-mortal scooping that is happening. Because you have to scoop the video and you also have to scoop the audio along with it. So lip syncing and everything else has to go hand in hand very well. So, if it was a Siri, then if he had spoken the word Gair Samrithane anywhere, anytime, you can pick up that word and insert it here. But since you have to do a complete multi-module scooping, multi-module generation of the attire, you need him to speak, you need a video of him speaking the same thing with lip syncing and everything and that has to be inserted in the middle and those three barbocca because the sentence has to flow in place. So, earlier, when we have AI based attire, this copy move used to do, this used to be a very simple copy paste here and there. Either cut copy paste, cut copy move is something we used to say. So, you have to delete, copy move, copy move, so there. But now what has happened and in the earlier days, it used to be just, if you have an audio of the person speaking those sentences or words, only then you could create this. But today, with this generative AI algorithm, what you can do is you can also create these complete instances of people speaking, even if they were not existing with you. So, this is a combination, this Amitrakha video that you just saw, Amitrakha video plus audio that we saw, it was a combination of copy move along with speed synthesis. Along with speed synthesis, that we were able to generate. So, not only speed synthesis, probably video synthesis also, that happened along with it. Because, if speed synthesis are away, the entire thing has to be shifted further back. The words are included. So, that is what you did. And then, audio splicing is, audio collage you, you can actually, so audio splicing would be similar to copy move, where copy move you were just shifting out. Audio splicing, when you can actually move out or words, completely or phrases, completely. So, earlier again, this used to be all non AI. Today, you can do all of it with AI. And what you will get is a lot more simplified version, a lot more smooth out version of the attacks. So, replay, you can do replay with using AI based attacks, you can do impersonations, you can do copy move, audio splicing, using all of it, using AI, generate way of a worker. And in AI based, the two main categories that you have is, you can do speed synthesis. So, in speed synthesis, what we do? In speed synthesis, we can have the complete speed synthesized, right? With you, and you can do it in, for so ever's voice, you want. So, did I play you that song of Ape Paslum and are you using some time in the past? You guys remember? You have to speak out. I am not able to see them. Chat. I mean, that time remember that there was no hope, it used to have had not been any song of Ape Paslum. You don't remember. I will search for it and I will show it to you. So, you could do a speed synthesis, so generate something completely in like a Amrish Puri's audio. So, that Amrish Puri's audio was a complete synthesis. We just have, we had completely new generation of that audio. And then you could do voice conversion. And in voice conversion, you can take whatever I am speaking. And you can have a present in let's say, prayer verse. Or you can have a present in Shams verse. So, the complete lecture is being given by any other student, be it Shambhit, anybody, instrae. So, the entire voice conversion can be done using AIPASl fans. So, this broad category of being able to impersonate or be able to create new things, change from one to other, this broad line of attacks is called as deep fake attacks. Images you have seen a lot of it in the general news and stuff. But this is very, very much possible, very much even prevalent, I would say.