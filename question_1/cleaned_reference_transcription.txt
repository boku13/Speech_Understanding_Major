we have we have been talking about these audio right audio processing with respect to speaker recognition speech recognition or or any such related task right but you also know that with any of these security technologies there can be attacks or there can be people who are who have any kind of ill intention who would to defraud the system right who would to fool the system have you heard of any such examples any such real world examples where any kind of security system is in place be it biometrics face voice any of those and there have been cases where these systems have been fooled anybody remembers any such instance would to share someone you have to speak up okay all right so so there have been several such instances not only in I'm audible right somebody please speak up i'm not able to hear you guys to see the text and all okay so there have been several such instances with with respect to different kinds of tasks automation tasks that we have been performing right and specifically in speech these are all the news clippings that you see of documented cases okay one of the interesting ones the the one that you see at the bottom City Bank launches voice passwords in India right so City Bank launched voice passwords you can gain access to accounts by using by speaking out your passwords and you would also see in capture right that you can you can speak out whatever so so there are image captures and then there are audio captures also that are there for people with special requirements they can speak out audio captures right so but these these can be fooled using using some of these technologies and this is what also happened in in some of these cases for example this Adobe Voco they have a Photoshop for voice which can lead to concerns we have robot speech simulator and and several other such things that that have been proposed in the literature and similar counterparts have also been proposed which can be used to defraud okay so specifically speaking this this line of research of presentation attack we call it or spoofing this has been in the community for 15 years or so now the research started the first competition around this it's called as the spoofing audio spoofing competition AASV audio spoofing verification competition we call it so this competition started I think around 2011 or so in the research community right at that time they were looking at some very specific kinds of attacks and I'll show you what those kinds of attacks were but these these compet competitions went they're still running those competitions are still running to evaluate the performance or of these attack detection algorithms or manipulation detection algorithms but after a few years that this research on presentation of spoofing started ISO got involved this international standards organization and they created a standards document on presentation attacks earlier we used to call it spoofing but then I also termed it as presentation attack so anything that is presented in front of a biometric system it can be attacked right so and then there are different kinds of attacks so the earlier the nomomenclature used to be real spool but then they proposed this nomenclature of bonafide and impostor so bonafide is a real one right so in this case with respect to face if you see bonafide is is the real face so you would enroll a real face a real face is coming as a query so so this is predicted as genuine right but then you could have impostors now what are those imposters imposter is anyone who's trying to fraudulently gain access to the system correct now this is something called as a zeroeffort imposter what is a zero effort impostor so let's say I want to gain access to your account right i just go in front of the biometric system and I give my biometric let's say that biometric is face or that biometric is audio i just give that biometric as you I just without any effort of trying to look you or trying to impersonate your voice or fingerprint whatever that modality is I just go using my characteristics and try to gain access to your account right so that is something called a zero effort impostor which is in which case it is very likely that I will not be able to gain access it'll be it'll be a failed attempt right but then there are cases in which one can get access and go back to Dodington Zoo when where we had these goat lamb sheeps and wolves right there are some cases there's some individuals who are easy to impersonate so if if these are easy to impersonate people even with zero effort impostor I I might be I might just be able to gain access depending on depending on a lot lot of characteristics lot of factors right but then what I can also do is do a bit more effort in trying to gain access to your account okay now in what ways can I try to gain access to your account let's say if it is audio in in what ways can I get access to your account can you think of it if I have to spoof an audio data an audio signal if you were given this task of spoofing what will you do how will you create a spoof of audio let's say you have to gain access to my account what will you do i'm waiting for the answers try to text u okay try to speak in your language my name is Richa please open the account okay so try to speak in my audio okay yes nearly must spoken in your sound likewise okay anything else record your voice and and then feed it record my voice and feed it that is good what else use a text to speech model and text that my name is Richa please open the account this type of thing that so that the models create an audio and feed that in the network we can also make a deep fake of your voice as well we can also make a deep fake of mine all right so all of these all of these are valid answers right and the the method of okay let me just play this audio signals for you in order to play this I think I'll have to go to the drive okay let me go to the drive just listen to this audio and tell me if it is Okay so whose voice is this shah Rukh Khan obviously right do you think it is a real voice of Shah Rukh Khan or this is any kind of AI attack you cannot hear the audio yeah we are not able to hear that you cannot hear my audio or you cannot hear the audio i just played videos yeah it goes that audio you couldn't hear the audio I played right yes ma'am okay let give me one second let me stop presenting can you hear now selfie post sorry okay well it is generated sound it is how it is generated sound sound some gaps in Shah's voice there is some gap he's used to speaking with gaps no yes yes anybody else would to give it a try okay let me play another one yes ma'am real I think real voice am puri okay no I don't think it's real the tone tonality is a little bit changed okay so so both of these guys are generated audios okay shah Rukh Khan as well as Amarish Puri this Amarish Purika audio was generated after he passed away right and this Shah Ruk Khan audio so there's this entire video that was generated a few years back by Cadbury's and they did they did a ad with Shah Ruk Khan's voice for local Kirana stores right because if you if If you hear the audio he's he's talking about local store and all of that right these guys can't afford Shah Rukh Khan these local Kirana stores and local uncle and auntie shops they can't afford Shah Rukh Khan so they Cadbury's used genai i think it was Cadbury's they used genai to create these create this entire ad right and that ad you can find that ad on YouTube it's it should be still there so benefit is you can create but then I don't know if they took permission from Shah Ruk Khan or not right you can you can create all all those sort of things and I mean you guys know that we're talking about Bix till we are having a discussion on whether it is fake or or not think about any normal person who who does not know the concept of defake so well that how good or how bad it is how would they differentiate between the two right so there's a there's an entire categorization of spoofing attacks you can generate samples based on AI methodologies and using some non-AI methodologies as well right so if we talk about obviously these non-AI methodologies came earlier and this when I was talking about the research started 15 years back we started with noni methodologies right and noni methodologies there are four five kinds of attacks which are more common ones the first one is your replay right so replay is I think Ravi Ravi suggested it earlier that what you can do is you have my you have my audio right now that I you have so many record audio samples of me from over multiple classes right if you want to gain access to my account you can you can take this audio and you can replay it whenever take out words or or do something of that sort and replay it to gain access to my account right so that is your replay attack okay to give you an example of replay with respect to a face this is this is how you can visualize it so this is your real or real frames from real video these are again your frames from real video but what you can do is you can record this video and replay it let's say I was trying to gain access to my KYC or my account or I want to be present in a meeting put attendance using a phase biometric system you can use that and gain access multiple times using that right so again several years back okay there there these school teachers in in some in some country I think it was Pakistan so so there was this grant coming in from United Nations for for school teachers and they were mandated to put attendance using phase biometrics because there was grant coming in for promoting school education in different countries so they said that we and stipend of and sorry and salaries of teachers and everybody was going in they kind of mandated that in order to ensure that teachers go to school every day so you have to go to school you have to put your you have to take a selfie and you have to post it on it on some server with with a date and time stamp so that your attendance is recorded right and based on that attendance the the salary was released every month right so so what some of the teachers used to do that what I'll do is today I'll take a picture I'll go to school I'll take five pictures for me okay and what I can do is tomorrow if I want to skip school I have multiple t pictures i'll take this picture and I'll click another picture of this from the phone okay or I'll take a I'll take a print out of this click another picture and upload this so the date and time stamp that comes with the photo in the metadata that will be for tomorrow because I clicked the photograph from the photograph the the the impersonation one that I had that I clicked tomorrow so then then date and time stamp will be fixed and I'll have my attendance marked right the same kind of thing can be done with respect to audio where you can capture these sentences and you can replay it again and again right so so today I go with the background and all I can capture the audio and wherever required I can replay the audio to gain access or to provide incorrect information or whatever is the requirement right so that is your replay attack impersonation impersonation is simple we understand that if you if you try to impersonate someone now and this impersonation can be done by different methods earlier this used to be nonI based and in nonI based it would be what would be nonI based impersonation it would be something we there are mimicry artists right there are mimicry artists who can very well mimic the audio of Shah Rukhan Amitab Bachan or or anybody right they can mimic anybody 's voice so so that mimicry would be that mimicry if used for impersonation would be considered as an attack and that that would be that that would be impersonation to gain access right the another one is copy move right what is copy move copy move is something where I can take an audio signal and take some parts of an audio from one place to other in the audio right and this I think happened in the elections this time when when we had general elections yeah when we had general election this time this is a news clipping I got from YouTube and let me just play this for you can see the screen the YouTube no ma'am the screen is not shared oh screen is not shared oh sorry sorry I the screen got unshared Okay can you see it now yes not able to hear voice oh you are again not able to hear the voice why is it doing this anybody knows ma'am I guess instead of sharing the screen you could share the tab that would allow us to hear the audio in the YouTube tab okay let me do that entire screen chrome tab okay can you hear this now yes okay let me just play the first audio very quickly see this is the first audio which was claimed to be the original audio right now let me play you the fake audio see what happened here lip is not sinking with voice lip is not voice okay what is the kind of attack what we are trying to do here so what they did in this is they took some they they they had the original video right they had the original video of Mr mita right and in some places they didn't change the entire audio or the entire video what they did this in between in the beginning of the speech he used this word they not they he used they inserted this word gamvidhanik right when he was referring to this they inserted the word g samvidhanik and then towards the end when he was saying that this reservation will continue they said it's s so in copy move what we do you take a word from somewhere and you insert it right or you can change phrases you have a phrase spoken at one place you pick up this phrase and you insert it somewhere else now in this case what they did was this this gam some viranic is probably the word which they might have found they might not have found anywhere to be in the same speech right now if you if they did not find that word in the same speech with the same attire because there's video also now see this is multimodel spoofing that is happening okay you have to spoof the video and you also have to spoof the audio along with So lip syncing and everything else has to go hand in hand very well right so sif audio to if he had spoken the word ganshanik anywhere any time you can pick up that word and insert it here right but since you have to you have to do a complete multimodel spoofing multimodel generation of u of the attack you need him to speak you need a video of him speaking the same thing with lip sync and everything and that has to be inserted in the middle and because the sentence has to flow in place right so earlier AI based attack this copy move we used to do this used to be a very simple copy paste here and there right either either cut cut copy paste cut copy move is something we used to say right so yeah to delete yeah copy move but now what has happened and and in that in earlier days it used to be just if you have an audio of the person speaking those sentences or words only then you could create this but today with this generative AI algorithms what you can do is you can also create these complete instances of of people speaking right even if they if they even if they weren't existing with you so this is a combination this Amit Shaka video that you just saw Amit Shaka video plus audio that we saw it was a combination of copy move along with speech synthesis right along with speed synthesis that we were able to generate so not only speech synthesis probably video synthesis also that happened along with it because s speech synthesis to the entire thing has to be shifted further back right words are introduced so so that is what we did right and then audio splicing is audio splice you can so audio splicing would be similar to copy move where copy move you was just shifting out audio splicing you can remove out words completely or phrases completely right so earlier again this used to be all nonI today you can do all of it with AI and what you'll get is a lot more simplified version not simplified a lot more smooth out version of the attacks right so replay say we can do replay with using AI based attacks you can do impersonation you can do copy move audio audio splicing using all of using AI generative AI algorithms right and in AI based the two main categories that you have is you can do speech Speech synthesis so in speech synthesis what we do in speech synthesis we can have the complete speech synthesized right with you and you can do it in whosoever's voice you want okay so did I play you that song of Araslam and Arajit Singh sometime in the past do you guys remember you have to speak out i am not able to see the chat in fact I remember that there was no means you have had not played any song of you don't remember okay I'll search for it and I'll I'll show it to you okay so you could do a speech synthesis so generate something completely in Amirish Puri's audio right so that Amarish Puri's audio was a complete synthesis we we just have we we we don't we had completely new generation of that audio right and then you could do voice conversion and in voice conversion you can you can take whatever I'm speaking and you can have it present in let's say Shrea's voice or you can have it present in Sham's voice so the complete lecture is being given by any other student be it Shria be it Sham be it anybody else right So so the entire voice conversion can be done using AI based attacks now this this broad category of being able to impersonate or being able to create new things change from one to other this this broad line of attacks is called as deep fake attacks images you have seen sign a lot of it in the in the general news and stuff but this is very very much possible very much even prevalent I would